<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Algorithms &amp; Maps</title>
    <link>/</link>
    <description>Recent content on Algorithms &amp; Maps</description>
    <generator>Hugo -- gohugo.io</generator>
    <managingEditor>csaybar@gmail.com (Cesar Aybar)</managingEditor>
    <webMaster>csaybar@gmail.com (Cesar Aybar)</webMaster>
    <lastBuildDate>Fri, 21 Jun 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Integrating Earth Engine with Tensorflow II - U-Net</title>
      <link>/post/eetf2/</link>
      <pubDate>Fri, 21 Jun 2019 00:00:00 +0000</pubDate>
      <author>csaybar@gmail.com (Cesar Aybar)</author>
      <guid>/post/eetf2/</guid>
      <description>This notebook has been inspired by the Chris Brown &amp;amp; Nick Clinton EarthEngine + Tensorflow presentation. It shows the step by step how to integrate Google Earth Engine and TensorFlow 2.0 in the same pipeline (EE-&amp;gt;Tensorflow-&amp;gt;EE).
  OBS: I will assume reader are already familiar with the basic concepts of Machine Learning and Convolutional Networks. If it is doesn’t, I firstly highly recommend taking the deep learning coursera specialization available here.</description>
    </item>
    
    <item>
      <title>Download the GLC30 product for Peru and Ecuador</title>
      <link>/post/landuseperu/</link>
      <pubDate>Sat, 08 Jun 2019 00:00:00 +0000</pubDate>
      <author>csaybar@gmail.com (Cesar Aybar)</author>
      <guid>/post/landuseperu/</guid>
      <description>Land Cover information is fundamental for environmental change studies, land resource management, sustainable development, and many other societal benefits. In Google Earth Engine existing different coarse Land use/cover products (e.g. MCD12Q1-500m) that are not able to capture the most significant human impacts on land systems due to its spatial resolution. Therefore, this short post aims to introduce and explain step by step how to download the GLC30 a relative new Global Land Cover product at 30-meter spatial resolution.</description>
    </item>
    
    <item>
      <title>Integrating Earth Engine with Tensorflow I - DNN</title>
      <link>/post/eetf/</link>
      <pubDate>Thu, 30 May 2019 00:00:00 +0000</pubDate>
      <author>csaybar@gmail.com (Cesar Aybar)</author>
      <guid>/post/eetf/</guid>
      <description>This notebook has been inspired by the Chris Brown &amp;amp; Nick Clinton EarthEngine + Tensorflow presentation. It shows the step by step how to integrate Google Earth Engine and TensorFlow 2.0 in the same pipeline (EE-&amp;gt;Tensorflow-&amp;gt;EE).
  Topics Create a training/testing dataset (in a TFRecord format) using Earth Engine. Create functions for parse data (TFRecord -&amp;gt; tf.</description>
    </item>
    
    <item>
      <title>Head Start Data Science I: Titanic Challenge</title>
      <link>/post/titanic/</link>
      <pubDate>Sun, 19 May 2019 00:00:00 +0000</pubDate>
      <author>csaybar@gmail.com (Cesar Aybar)</author>
      <guid>/post/titanic/</guid>
      <description>1. Introduction The Titanic challenge is an excellent way to practice the necessary skills required for ML. In my first attempts, I blindly applied a well-known ML method (Lightgbm); however, I couldn’t go up over the Top 20% :(. To have success in this competition you need to realize an acute feature engineering that takes into account the distribution on train and test dataset. This post is the perfect opportunity to share with you my Python package preml and show how can you BEAT THE 97% OF LB.</description>
    </item>
    
    <item>
      <title>How to create 3D Interactive choropleth map in R</title>
      <link>/post/plotlyformaps_i/</link>
      <pubDate>Sat, 12 Jan 2019 00:00:00 +0000</pubDate>
      <author>csaybar@gmail.com (Cesar Aybar)</author>
      <guid>/post/plotlyformaps_i/</guid>
      <description>1. Intro A Choropleth map is a thematic map in which areas are colored considering the quantitative measurement of a variable, such as population density or gross domestic product.
There are a lot of libraries in R (and of course in Python too) that perform it efficiently. However, I feel that ggplot2 offers the fastest and most friendly way. Don’t you believe me? Look at this.</description>
    </item>
    
    <item>
      <title>Raster resampling in R</title>
      <link>/post/resample/</link>
      <pubDate>Wed, 05 Dec 2018 00:00:00 +0000</pubDate>
      <author>csaybar@gmail.com (Cesar Aybar)</author>
      <guid>/post/resample/</guid>
      <description>1. Intro A typical workflow for earth analysts always will have to do with several spatial data sources (e.g. Sentinel, MODIS and Landsat) each one with a particular extent and pixel resolution. Resampling is the technique used to homogenize these spatial attributes.
Image obtained from here
 This post demonstrates how easy and incredibly fast is resampling gridded data in R using either the raster and gdalUtils packages.</description>
    </item>
    
    <item>
      <title></title>
      <link>/page/projects/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <author>csaybar@gmail.com (Cesar Aybar)</author>
      <guid>/page/projects/</guid>
      <description>-I don’t update this page as much, so head to my GitHub for the most recent projects
1. Coursera Deep Learning in Colab This Github repo contains multiple Colab iPython notebooks which serve as tutorials for learning about deploying deep learning and machine learning models. All the material is part of the Coursera Deep Learning Specialization.
The following topics are covered:
 1. Neural Networks and Deep Learning: In this course, you will learn the foundations of deep learning.</description>
    </item>
    
    <item>
      <title>About me</title>
      <link>/page/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <author>csaybar@gmail.com (Cesar Aybar)</author>
      <guid>/page/about/</guid>
      <description>Looking back ~5 years ago, there was one thing which diversified my thoughts and changes the course of my career: Discover Linux and installs Debian Wheezy on my old computer (a Pentium 4). After that one thing led to another.
I am passionate about data that nowadays works at SENAMHI solving complex problems, always in the best possible way. When I&amp;rsquo;m not in the office coding or writing reports. I am playing the violin (although without much success … for now!</description>
    </item>
    
  </channel>
</rss>