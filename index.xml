<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>csaybar</title>
    <link>http://csaybar.github.io/</link>
    <description>Recent content on csaybar</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 15 Jun 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="http://csaybar.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>rgee example #2: Satellite image preprocessing</title>
      <link>http://csaybar.github.io/blog/2020/06/15/rgee_02_io/</link>
      <pubDate>Mon, 15 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>http://csaybar.github.io/blog/2020/06/15/rgee_02_io/</guid>
      <description>Image preprocessing (i.e. download, reprojection, mosaicking, resize, bad pixels control and composite) has always been a time-consuming activity. Although R offers incredible open-source “API packages” to easily get geospatial resources (modistsp, getSpatialData, elevation, landsat and so on …), these still require that users count with competent computers (and high-end for users that want to analysis large areas).</description>
    </item>
    
    <item>
      <title>rgee example #1: Creating static and interactive maps</title>
      <link>http://csaybar.github.io/blog/2020/06/10/rgee_01_worldmap/</link>
      <pubDate>Wed, 10 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>http://csaybar.github.io/blog/2020/06/10/rgee_01_worldmap/</guid>
      <description>Scientific and data analytics are constantly wrangling data and creating visualizations to explain their results. If you are working with structured data, R packages like tidyverse or data.table are probably making your life very pleasant. But what happens for unstructured spatial data?. For instance, if your boss (advisor) asks you to dig through a giant pile of MODIS images, what R package would you use?</description>
    </item>
    
    <item>
      <title>Download the GLC30 product for Peru and Ecuador</title>
      <link>http://csaybar.github.io/blog/2019/10/10/landuseperu/</link>
      <pubDate>Thu, 10 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>http://csaybar.github.io/blog/2019/10/10/landuseperu/</guid>
      <description>Land Cover information is fundamental for environmental change studies, land resource management, sustainable development, and many other societal benefits. In Google Earth Engine existing different coarse Land use/cover products (e.g. MCD12Q1-500m) that are not able to capture the most significant human impacts on land systems due to its spatial resolution. Therefore, this short post aims to introduce and explain step by step how to download the GLC30 a relative new Global Land Cover product at 30-meter spatial resolution.</description>
    </item>
    
    <item>
      <title>Integrating Earth Engine with Tensorflow II - U-Net</title>
      <link>http://csaybar.github.io/blog/2019/06/21/eetf2/</link>
      <pubDate>Fri, 21 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>http://csaybar.github.io/blog/2019/06/21/eetf2/</guid>
      <description>This notebook has been inspired by the Chris Brown &amp;amp; Nick Clinton EarthEngine + Tensorflow presentation. It shows the step by step how to integrate Google Earth Engine and TensorFlow 2.0 in the same pipeline (EE-&amp;gt;Tensorflow-&amp;gt;EE).
  OBS: I will assume reader are already familiar with the basic concepts of Machine Learning and Convolutional Networks. If it is doesn’t, I firstly highly recommend taking the deep learning coursera specialization available here.</description>
    </item>
    
    <item>
      <title>Integrating Earth Engine with Tensorflow I - DNN</title>
      <link>http://csaybar.github.io/blog/2019/05/30/eetf/</link>
      <pubDate>Thu, 30 May 2019 00:00:00 +0000</pubDate>
      
      <guid>http://csaybar.github.io/blog/2019/05/30/eetf/</guid>
      <description>This notebook has been inspired by the Chris Brown &amp;amp; Nick Clinton EarthEngine + Tensorflow presentation. It shows the step by step how to integrate Google Earth Engine and TensorFlow 2.0 in the same pipeline (EE-&amp;gt;Tensorflow-&amp;gt;EE).
  Topics Create a training/testing dataset (in a TFRecord format) using Earth Engine. Create functions for parse data (TFRecord -&amp;gt; tf.</description>
    </item>
    
    <item>
      <title>Head Start Data Science I: Titanic Challenge</title>
      <link>http://csaybar.github.io/blog/2019/05/19/titanic/</link>
      <pubDate>Sun, 19 May 2019 00:00:00 +0000</pubDate>
      
      <guid>http://csaybar.github.io/blog/2019/05/19/titanic/</guid>
      <description>1. Introduction The Titanic challenge is an excellent way to practice the necessary skills required for ML. In my first attempts, I blindly applied a well-known ML method (Lightgbm); however, I couldn’t go up over the Top 20% :(. To have success in this competition you need to realize an acute feature engineering that takes into account the distribution on train and test dataset. This post is the perfect opportunity to share with you my Python package preml and show how can you BEAT THE 97% OF LB.</description>
    </item>
    
    <item>
      <title>How to create 3D Interactive choropleth map in R</title>
      <link>http://csaybar.github.io/blog/2019/01/12/plotlyformaps_i/</link>
      <pubDate>Sat, 12 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>http://csaybar.github.io/blog/2019/01/12/plotlyformaps_i/</guid>
      <description>1. Introduction A Choropleth map is a thematic map in which areas are colored considering the quantitative measurement of a variable, such as population density or gross domestic product.
There are a lot of libraries in R (and of course in Python too) that perform it efficiently. However, I feel that ggplot2 offers the fastest and most friendly way. Don’t you believe me? Look at this.</description>
    </item>
    
    <item>
      <title>Raster resampling in R</title>
      <link>http://csaybar.github.io/blog/2018/12/05/resample/</link>
      <pubDate>Wed, 05 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>http://csaybar.github.io/blog/2018/12/05/resample/</guid>
      <description>1. Introduction A typical workflow for earth analysts always will have to do with several spatial data sources (e.g. Sentinel, MODIS and Landsat) each one with a particular extent and pixel resolution. Resampling is the technique used to homogenize these spatial attributes.
Image obtained from here
 This post demonstrates how easy and incredibly fast is resampling gridded data in R using either the raster and gdalUtils packages.</description>
    </item>
    
    <item>
      <title></title>
      <link>http://csaybar.github.io/teaching/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://csaybar.github.io/teaching/</guid>
      <description>Teaching /*! jQuery v1.11.3 | (c) 2005, 2015 jQuery Foundation, Inc. | jquery.org/license */ !function(a,b){&#34;object&#34;==typeof module&amp;&amp;&#34;object&#34;==typeof module.exports?module.exports=a.document?b(a,!0):function(a){if(!a.document)throw new Error(&#34;jQuery requires a window with a document&#34;);return b(a)}:b(a)}(&#34;undefined&#34;!=typeof window?window:this,function(a,b){var c=[],d=c.slice,e=c.concat,f=c.push,g=c.indexOf,h={},i=h.toString,j=h.hasOwnProperty,k={},l=&#34;1.11.3&#34;,m=function(a,b){return new m.fn.init(a,b)},n=/^[\s\uFEFF\xA0]+|[\s\uFEFF\xA0]+$/g,o=/^-ms-/,p=/-([\da-z])/gi,q=function(a,b){return b.toUpperCase()};m.fn=m.prototype={jquery:l,constructor:m,selector:&#34;&#34;,length:0,toArray:function(){return d.call(this)},get:function(a){return null!=a?0a?this[a+this.length]:this[a]:d.call(this)},pushStack:function(a){var b=m.merge(this.constructor(),a);return b.prevObject=this,b.context=this.context,b},each:function(a,b){return m.each(this,a,b)},map:function(a){return this.pushStack(m.map(this,function(b,c){return a.call(b,c,b)}))},slice:function(){return this.pushStack(d.apply(this,arguments))},first:function(){return this.eq(0)},last:function(){return this.eq(-1)},eq:function(a){var b=this.length,c=+a+(0a?b:0);return this.pushStack(c=0&amp;&amp;bc?[this[c]]:[])},end:function(){return this.prevObject||this.constructor(null)},push:f,sort:c.sort,splice:c.splice},m.extend=m.fn.extend=function(){var a,b,c,d,e,f,g=arguments[0]||{},h=1,i=arguments.length,j=!1;for(&#34;boolean&#34;==typeof g&amp;&amp;(j=g,g=arguments[h]||{},h++),&#34;object&#34;==typeof g||m.isFunction(g)||(g={}),h===i&amp;&amp;(g=this,h--);ih;h++)if(null!=(e=arguments[h]))for(d in e)a=g[d],c=e[d],g!==c&amp;&amp;(j&amp;&amp;c&amp;&amp;(m.isPlainObject(c)||(b=m.isArray(c)))?(b?(b=!1,f=a&amp;&amp;m.isArray(a)?a:[]):f=a&amp;&amp;m.isPlainObject(a)?a:{},g[d]=m.extend(j,f,c)):void 0!==c&amp;&amp;(g[d]=c));return g},m.extend({expando:&#34;jQuery&#34;+(l+Math.random()).replace(/\D/g,&#34;&#34;),isReady:!0,error:function(a){throw new Error(a)},noop:function(){},isFunction:function(a){return&#34;function&#34;===m.type(a)},isArray:Array.isArray||function(a){return&#34;array&#34;===m.type(a)},isWindow:function(a){return null!=a&amp;&amp;a==a.window},isNumeric:function(a){return!m.isArray(a)&amp;&amp;a-parseFloat(a)+1=0},isEmptyObject:function(a){var b;for(b in a)return!1;return!0},isPlainObject:function(a){var b;if(!a||&#34;object&#34;!==m.type(a)||a.nodeType||m.isWindow(a))return!1;try{if(a.constructor&amp;&amp;!j.call(a,&#34;constructor&#34;)&amp;&amp;!j.call(a.constructor.prototype,&#34;isPrototypeOf&#34;))return!1}catch(c){return!1}if(k.ownLast)for(b in a)return j.call(a,b);for(b in a);return void 0===b||j.call(a,b)},type:function(a){return null==a?a+&#34;&#34;:&#34;object&#34;==typeof a||&#34;function&#34;==typeof a?h[i.call(a)]||&#34;object&#34;:typeof a},globalEval:function(b){b&amp;&amp;m.trim(b)&amp;&amp;(a.execScript||function(b){a.eval.call(a,b)})(b)},camelCase:function(a){return a.</description>
    </item>
    
    <item>
      <title>Contact</title>
      <link>http://csaybar.github.io/contact/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://csaybar.github.io/contact/</guid>
      <description>How can I help you? Thank you for visiting my site. Please feel free to contact me. I am always interested in making academic and outreach collaborations.</description>
    </item>
    
    <item>
      <title>FAQ</title>
      <link>http://csaybar.github.io/faq/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://csaybar.github.io/faq/</guid>
      <description>Pellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas. Vestibulum tortor quam, feugiat vitae, ultricies eget, tempor sit amet, ante. Donec eu libero sit amet quam egestas semper. Aenean ultricies mi vitae est. Mauris placerat eleifend leo.
1. WHAT TO DO IF I HAVE STILL NOT RECEIVED THE ORDER? Pellentesque habitant morbi tristique senectus et netus et malesuada fames ac turpis egestas. Vestibulum tortor quam, feugiat vitae, ultricies eget, tempor sit amet, ante.</description>
    </item>
    
    <item>
      <title>Publications</title>
      <link>http://csaybar.github.io/publications/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://csaybar.github.io/publications/</guid>
      <description>Complete list of publications on Google Scholar
Book  Andrade, M.F., Moreno, I., Calle, J.M., Ticona, L., Blacutt, L., Lavado-Casimiro, W., Sabino, E., Huerta, A., Aybar, C., Hunziker, S. and Brönnimann, S., 2018. Climate and extreme events from the Central Altiplano of Peru and Bolivia.  Refereed Journal Articles  Aybar, C., Fernández, C., Huerta, A., Lavado, W., Vega, F., &amp;amp; Felipe-Obando, O. (2019). Construction of a high-resolution gridded rainfall dataset for Peru from 1981 to the present day.</description>
    </item>
    
    <item>
      <title>Research</title>
      <link>http://csaybar.github.io/research/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://csaybar.github.io/research/</guid>
      <description>Construction of a high-resolution gridded rainfall dataset for Peru from 1981 to the present day A new gridded rainfall dataset available for Peru is introduced, called PISCOp V2.1 (Peruvian Interpolated data of SENAMHI’s Climatological and Hydrological Observations). PISCOp has been developed for the period 1981 to the present, with an average latency of eight weeks at 0.1° spatial resolution. The merging algorithm is based on geostatistical and deterministic interpolation methods including three different rainfall sources: (i) the national quality-controlled and infilled raingauge dataset, (ii) radar-gauge merged precipitation climatologies and (iii) the Climate Hazards Group Infrared Precipitation (CHIRP) estimates.</description>
    </item>
    
    <item>
      <title>Software</title>
      <link>http://csaybar.github.io/software/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://csaybar.github.io/software/</guid>
      <description>Google Earth Engine for R Google Earth Engine is a cloud-based platform that allows users getting access to a petabyte-scale archive of remote sensing data and run geospatial analysis on Google’s infrastructure. The rgee package provides full access to the Google Earth Engine API from within R and defines additional tools for automating processes...
Continue reading
     DeforestGAN: Quasi-real-time vegetation maps DeforestGAN uses a conditional adversary generative neural network to simulate NDVI values from SENTINEL-1 radar images.</description>
    </item>
    
    <item>
      <title>Teaching</title>
      <link>http://csaybar.github.io/teaching/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://csaybar.github.io/teaching/</guid>
      <description>Teaching material   [SPA] Conference at MASTERGIS   Use of Google Earth Engine, Tensorflow and neural networks in Remote Sensing.    
Courses at undergraduate level  
University of San Marcos, Peru Introduction to computer science and algorithms, 2018 Tutor  Based on the Khan Academy algorithm course  and Thomas H. Cormen book, this course introduces students searching, sorting, and recursion algorithms using Python. Material with respect to visualizations and coding challenges were added.</description>
    </item>
    
  </channel>
</rss>