<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Blogs on csaybar</title>
    <link>/blog/</link>
    <description>Recent content in Blogs on csaybar</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 10 Oct 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/blog/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Download the GLC30 product for Peru and Ecuador</title>
      <link>/blog/2019/10/10/landuseperu/</link>
      <pubDate>Thu, 10 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/2019/10/10/landuseperu/</guid>
      <description>Land Cover information is fundamental for environmental change studies, land resource management, sustainable development, and many other societal benefits. In Google Earth Engine existing different coarse Land use/cover products (e.g. MCD12Q1-500m) that are not able to capture the most significant human impacts on land systems due to its spatial resolution. Therefore, this short post aims to introduce and explain step by step how to download the GLC30 a relative new Global Land Cover product at 30-meter spatial resolution.</description>
    </item>
    
    <item>
      <title>Integrating Earth Engine with Tensorflow II - U-Net</title>
      <link>/blog/2019/06/21/eetf2/</link>
      <pubDate>Fri, 21 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/2019/06/21/eetf2/</guid>
      <description>This notebook has been inspired by the Chris Brown &amp;amp; Nick Clinton EarthEngine + Tensorflow presentation. It shows the step by step how to integrate Google Earth Engine and TensorFlow 2.0 in the same pipeline (EE-&amp;gt;Tensorflow-&amp;gt;EE).
  OBS: I will assume reader are already familiar with the basic concepts of Machine Learning and Convolutional Networks. If it is doesn’t, I firstly highly recommend taking the deep learning coursera specialization available here.</description>
    </item>
    
    <item>
      <title>Integrating Earth Engine with Tensorflow I - DNN</title>
      <link>/blog/2019/05/30/eetf/</link>
      <pubDate>Thu, 30 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/2019/05/30/eetf/</guid>
      <description>This notebook has been inspired by the Chris Brown &amp;amp; Nick Clinton EarthEngine + Tensorflow presentation. It shows the step by step how to integrate Google Earth Engine and TensorFlow 2.0 in the same pipeline (EE-&amp;gt;Tensorflow-&amp;gt;EE).
  Topics Create a training/testing dataset (in a TFRecord format) using Earth Engine. Create functions for parse data (TFRecord -&amp;gt; tf.</description>
    </item>
    
    <item>
      <title>Head Start Data Science I: Titanic Challenge</title>
      <link>/blog/2019/05/19/titanic/</link>
      <pubDate>Sun, 19 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/2019/05/19/titanic/</guid>
      <description>1. Introduction The Titanic challenge is an excellent way to practice the necessary skills required for ML. In my first attempts, I blindly applied a well-known ML method (Lightgbm); however, I couldn’t go up over the Top 20% :(. To have success in this competition you need to realize an acute feature engineering that takes into account the distribution on train and test dataset. This post is the perfect opportunity to share with you my Python package preml and show how can you BEAT THE 97% OF LB.</description>
    </item>
    
    <item>
      <title>How to create 3D Interactive choropleth map in R</title>
      <link>/blog/2019/01/12/plotlyformaps_i/</link>
      <pubDate>Sat, 12 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/blog/2019/01/12/plotlyformaps_i/</guid>
      <description>1. Introduction A Choropleth map is a thematic map in which areas are colored considering the quantitative measurement of a variable, such as population density or gross domestic product.
There are a lot of libraries in R (and of course in Python too) that perform it efficiently. However, I feel that ggplot2 offers the fastest and most friendly way. Don’t you believe me? Look at this.</description>
    </item>
    
    <item>
      <title>Raster resampling in R</title>
      <link>/blog/2018/12/05/resample/</link>
      <pubDate>Wed, 05 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/blog/2018/12/05/resample/</guid>
      <description>1. Introduction A typical workflow for earth analysts always will have to do with several spatial data sources (e.g. Sentinel, MODIS and Landsat) each one with a particular extent and pixel resolution. Resampling is the technique used to homogenize these spatial attributes.
Image obtained from here
 This post demonstrates how easy and incredibly fast is resampling gridded data in R using either the raster and gdalUtils packages.</description>
    </item>
    
  </channel>
</rss>